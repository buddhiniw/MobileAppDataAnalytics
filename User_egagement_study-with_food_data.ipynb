{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color=blue>USER ENGAGEMENT STUDY</font>\n",
    "\n",
    "***\n",
    "From Ref : https://clearbridgemobile.com/5-methods-for-increasing-app-engagement-user-retention/ <br>\n",
    "Engagement â€“ describes how active users are on the application. While this is a somewhat subjective metric, Localytics describes highly engaged users as those that have 10+ sessions per month.<br>\n",
    "\n",
    "Metrics to study:\n",
    "0. Retention rate and churn rate\n",
    "1. Session length (time between opening and closing of app)\n",
    "2. Time interval between two consecuitive sessions\n",
    "3. Screen flows\n",
    "4. App crashes\n",
    "5. Daily uninstalls (new vs exsisting users, android vs ios)\n",
    "6. Track App Launch to App Launch Retention Cohorts\n",
    "7. Track Active Users: DAUs (daily Active Users), MAUs (Monthly Active Users), Stickiness = DAU/MAU\n",
    "8. Track Number of Daily/Monthly Sessions\n",
    "\n",
    "More references:\n",
    "https://blog.appsee.com/the-best-metrics-and-tools-for-measuring-user-engagement/ <br>\n",
    "https://clevertap.com/blog/cohort-analysis-user-retention/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn import cluster\n",
    "#from collections import defaultdict\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "\n",
    "#from matplotlib import cm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "\n",
    "#from sklearn.metrics.cluster import normalized_mutual_info_score\n",
    "#from sklearn.metrics.cluster import adjusted_rand_score\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_encoding(df, col_name):\n",
    "    df[col_name] = c_df[col_name].astype('category')\n",
    "    df[col_name+\"_CAT\"] = c_df[col_name].cat.codes\n",
    "    return\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color=green>1. USER RETENTION AND CHURN RATE</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the study I am going to use a sample dataset I found online called chapter-12-relay-foods.csv. <br> It is from reference http://www.gregreda.com/2015/08/23/cohort-analysis-with-python/#2.-Determine-the-user's-cohort-group-(based-on-their-first-order) <br> which is the tutorial I am going to follow to estimate the user retention. <br>\n",
    "\n",
    "NOTE <br> \n",
    "I will add the variables I think we should use from InstaSize dataset in double parenthisis (()) so that it is easy to insert them and study when we get a larger sample dataset. I have run this code on the current InstaSize sample dataset but there aren't enough data to draw a rentetion curve."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the FOOD Data Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "IOError",
     "evalue": "File tute_data/chapter-12-relay-foods.csv does not exist",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIOError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-2e1ebd611946>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Open the test data set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"tute_data/chapter-12-relay-foods.csv\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mparse_dates\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'OrderDate'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/buddhini/.local/lib/python2.7/site-packages/pandas/io/parsers.pyc\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, skipfooter, doublequote, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    676\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[1;32m    677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 678\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    679\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    680\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/buddhini/.local/lib/python2.7/site-packages/pandas/io/parsers.pyc\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    438\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    439\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 440\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    441\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    442\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/buddhini/.local/lib/python2.7/site-packages/pandas/io/parsers.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    785\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    786\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 787\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    788\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    789\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/buddhini/.local/lib/python2.7/site-packages/pandas/io/parsers.pyc\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1012\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'c'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1013\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'c'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1014\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1015\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1016\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'python'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/buddhini/.local/lib/python2.7/site-packages/pandas/io/parsers.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1706\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'usecols'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1707\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1708\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1709\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1710\u001b[0m         \u001b[0mpassed_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnames\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mIOError\u001b[0m: File tute_data/chapter-12-relay-foods.csv does not exist"
     ]
    }
   ],
   "source": [
    "# Open the data file and read the contents into a dataframe\n",
    "#df=pd.read_csv(\"SFData5Users.csv\",parse_dates=['FIRST_SESSION_DATE'])\n",
    "#df.describe()\n",
    "\n",
    "# Open the test data set\n",
    "df=pd.read_csv(\"tute_data/chapter-12-relay-foods.csv\",parse_dates=['OrderDate'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-processing (required for the final analysis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep only the ones required for this analysis\n",
    "#keep_col = ['CUSTOMER_ID','CLIENT_DATE','CLIENT_TIME','SESSION_UUID','FIRST_SESSION_DATE']\n",
    "#df = df[keep_col]\n",
    "#df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find columns with null values\n",
    "print(df.isnull().sum())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cohort Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reference - http://www.gregreda.com/2015/08/23/cohort-analysis-with-python/ <br>\n",
    "\n",
    "What is cohort analysis? <br>\n",
    "A cohort is a group of users who share something in common like their sign-up date, first purchase month, birth date, acquisition channel, etc. Cohort analysis is the method by which these groups are tracked over time, helping us to spot trends, understand repeat behaviors (purchases, engagement, amount spent, etc.), and monitor customer and revenue retention. <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Create a period column and a year column based on the OrderDate ((FIRST_SESSION_DATE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df['FIRST_SESSION_PERIOD'] = df.FIRST_SESSION_DATE.apply(lambda x: x.strftime('%Y-%m'))\n",
    "df['OrderYear'] = df.OrderDate.apply(lambda x: x.strftime('%Y'))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Determine the user's cohort group based on their order ((first session))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new column called CohortGroup, which is the year and month in which the user's first started using the app.\n",
    "#df.set_index('CUSTOMER_ID', inplace=True)\n",
    "#df['COHORT_GROUP'] = df.groupby(level=0)['FIRST_SESSION_DATE'].min().apply(lambda x: x.strftime('%Y-%m'))\n",
    "df.set_index('UserId', inplace=True)\n",
    "df['CohortGroup'] = df.groupby(level=0)['OrderDate'].min().apply(lambda x: x.strftime('%Y-%m'))\n",
    "df.reset_index(inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Rollup data by CohortGropu & OrderDate ((COHORT_GROUP & FIRST_SESSION_DATE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#grouped = df.groupby(['COHORT_GROUP', 'FIRST_SESSION_PERIOD'])\n",
    "grouped = df.groupby(['CohortGroup', 'OrderPeriod'])\n",
    "\n",
    "# count the unique users, orders, and total revenue per Group + Period\n",
    "#cohorts = grouped.agg({'CUSTOMER_ID': pd.Series.nunique,'SESSION_UUID': pd.Series.nunique})\n",
    "cohorts = grouped.agg({'UserId': pd.Series.nunique,'OrderId': pd.Series.nunique})\n",
    "\n",
    "# make the column names more meaningful\n",
    "#cohorts.rename(columns={'CUSTOMER_ID': 'TOTAL_CUSTOMERS', 'SESSION_UUID': 'TOTAL_SESSIONS'}, inplace=True)\n",
    "cohorts.rename(columns={'UserId': 'TotalUsers', 'OrderId': 'TotalOrders'}, inplace=True)\n",
    "\n",
    "cohorts\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Label the COHORT_GROUP for each CohortGroupÂ¶\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check how each cohort has behaved in the months following their first session.\n",
    "# This allows us to compare cohorts across various stages of their lifetime.\n",
    "# To do this we need to index each cohort to their first session month. \n",
    "def cohort_period(df):\n",
    "    #df['COHORT_PERIOD'] = np.arange(len(df)) + 1\n",
    "    df['CohortPeriod'] = np.arange(len(df)) + 1\n",
    "    return df\n",
    "\n",
    "cohorts = cohorts.groupby(level=0).apply(cohort_period)\n",
    "cohorts\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## User Retention by Cohort Group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We look at the percentage change of each CohortGroup over time \n",
    "\n",
    "# reindex the DataFrame\n",
    "cohorts.reset_index(inplace=True)\n",
    "\n",
    "#cohorts.set_index(['COHORT_GROUP', 'COHORT_PERIOD'], inplace=True)\n",
    "cohorts.set_index(['CohortGroup', 'CohortPeriod'], inplace=True)\n",
    "\n",
    "# create a Series holding the total size of each CohortGroup\n",
    "#cohort_group_size = cohorts['TOTAL_CUSTOMERS'].groupby(level=0).first()\n",
    "cohort_group_size = cohorts['TotalOrders'].groupby(level=0).first()\n",
    "\n",
    "cohort_group_size.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now, we'll need to divide the TotalUsers values in cohorts by cohort_group_size. \n",
    "# Since DataFrame operations are performed based on the indices of the objects, we'll use unstack \n",
    "# on our cohorts DataFrame to create a matrix where each column represents a CohortGroup and \n",
    "# each row is the CohortPeriod corresponding to that group.\n",
    "\n",
    "#cohorts['TOTAL_CUSTOMERS'].unstack(0).head()\n",
    "cohorts['TotalOrders'].unstack(0).head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now utilize broadcasting to divide each column by the corresponding cohort_group_size.\n",
    "\n",
    "#user_retention = cohorts['TOTAL_CUSTOMERS'].unstack(0).divide(cohort_group_size, axis=1)\n",
    "user_retention = cohorts['TotalOrders'].unstack(0).divide(cohort_group_size, axis=1)\n",
    "\n",
    "user_retention.head(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retention Rate Trend "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the cohorts over time in an effort to spot behavioral differences or similarities.\n",
    "#user_retention[['2018-06', '2018-07']].plot(figsize=(10,5))\n",
    "#user_retention[['2009-01', '2009-02', '2010-01']].plot(figsize=(10,5))\n",
    "user_retention.plot(figsize=(10,5))\n",
    "\n",
    "plt.title('Cohorts: User Retention')\n",
    "plt.xticks(np.arange(1, 12.1, 1))\n",
    "plt.xlim(1, 12)\n",
    "#plt.ylabel('% of Active users');\n",
    "#plt.xlabel('Months following first session');\n",
    "plt.ylabel('% of Cohort Purchasing');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retention Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(style='white')\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.title('Cohorts: User Retention')\n",
    "sns.heatmap(user_retention.T, mask=user_retention.T.isnull(), annot=True, fmt='.0%');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Monthly Retention or the percent of users who return to the app one month, two months, and three months after the app is downloaded.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To estimate this take the average for each of the cohorts in period 1, 2 and 3 seperately.\n",
    "# Seperate years 2009 and 2010\n",
    "monthly_retention = user_retention.groupby(user_retention.columns.str.split(\"-\").str[0],axis=1).mean()\n",
    "monthly_retention.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select all cases where CohortPeriod < 4\n",
    "list(monthly_retention.index)\n",
    "select_indices = list(np.where(monthly_retention[\"\"] == True)[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "monthly_retention.plot(y='2009', use_index=True, figsize=(10,5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create plot\n",
    "n_groups = len(monthly_retention.columns)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "index = np.arange(n_groups)\n",
    "bar_width = 0.35\n",
    "opacity = 0.8\n",
    " \n",
    "rects1 = plt.bar(index, monthly_retention, bar_width,\n",
    "                 alpha=opacity,\n",
    "                 color='b',\n",
    "                 label='Frank')\n",
    " \n",
    "\n",
    " \n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
